# DataChat

A modular, RAG-powered GenAI platform that enables natural language querying across multiple data sources.

## ğŸ¯ Overview

This platform acts as an intelligent interface layer between users and data infrastructure, converting natural language questions into SQL queries, executing them safely, and interpreting results into business insights.

## âœ¨ Key Features

- **Natural Language Querying**: Ask questions in plain English.
- **Intelligent SQL Generation**: Advanced prompt engineering for JOINs, aggregations, and complex logic.
- **Multi-Source Config**: Manage multiple database connections via `config/sources.yaml`.
- **RAG Integration**: Query unstructured documentation and policies via ChromaDB.
- **Autonomous Error Correction**: Self-healing query execution with LLM-powered feedback loops.
- **Safe Execution**: Strict validation classes for every SQL dialect (Postgres, MySQL, Redshift, BigQuery, etc.).
- **NoSQL Support**: Query DynamoDB using PartiQL with automatic complexity validation.
- **Result Interpretation**: Transform raw data into actionable insights using rich context.
- **Modular Architecture**: Pluggable connectors, LLMs (Gemini, Anthropic, OpenAI), and vector stores.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Application Layer                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Streamlit   â”‚         â”‚     FastAPI          â”‚  â”‚
â”‚  â”‚     UI       â”‚         â”‚       API            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Orchestration Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Query Orchestrator                   â”‚   â”‚
â”‚  â”‚  â€¢ Context Building                          â”‚   â”‚
â”‚  â”‚  â€¢ SQL Generation                            â”‚   â”‚
â”‚  â”‚  â€¢ Validation & Execution                    â”‚   â”‚
â”‚  â”‚  â€¢ Result Interpretation                     â”‚   â”‚
â”‚  â”‚  â€¢ Caching (Redis) & Metrics                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   LLM      â”‚          â”‚   Connector    â”‚
    â”‚  Provider  â”‚          â”‚     Layer      â”‚
    â”‚            â”‚          â”‚                â”‚
    â”‚  OpenAI    â”‚          â”‚  Postgres/MySQLâ”‚
    â”‚ Anthropic  â”‚          â”‚   BigQuery     â”‚
    â”‚  Gemini    â”‚          â”‚   Redshift     â”‚
    â”‚  Ollama    â”‚          â”‚   DynamoDB     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Observability Stack                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Prometheus  â”‚â†â”€â”€â”‚  Metrics   â”‚   â”‚  Grafana  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> [!TIP]
> View the detailed visual flow in [FLOW_DIAGRAM.mermaid](file:///home/sumit/workspace/datachat/docs/FLOW_DIAGRAM.mermaid).

## ğŸ“‹ Prerequisites

- Docker & Docker Compose
- OpenAI API Key (or other LLM provider key)

## ğŸš€ Quick Start

### 1. Clone and Configure

```bash
# Clone the repository
git clone <repository-url>
cd genai-data-platform

# Create .env file
cp .env.example .env
```

### 2. Configure Environment

Edit `.env` and add your API keys:

```bash
OPENAI_API_KEY=sk-...your-key-here...
# Database credentials if using external DB (optional for testing)
```

### 3. Run with Docker Compose

The easiest way to run the full platform (API, UI, Redis, Prometheus, Grafana) is via Docker:

```bash
docker-compose up --build
```

### 4. Access the Platform

- **Streamlit UI**: `http://localhost:8501`
  - **Login**: `admin` / `admin` (Default mock credentials)
- **FastAPI Docs**: `http://localhost:8000/docs`
- **Grafana Dashboards**: `http://localhost:3000` (Default: `admin` / `admin`)
- **Prometheus**: `http://localhost:9090`

### 5. Manual Setup (Dev Mode)

If you prefer running locally without Docker:

```bash
# Create venv
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Start Redis (Required)
docker run -d -p 6379:6379 redis:alpine

# Start API
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Start UI (New Terminal)
streamlit run src/ui/streamlit_app.py
```

## ğŸ’¡ Usage Examples

### Using the Chat UI

1. Open the Streamlit UI at `http://localhost:8501`
2. View the database schema in the sidebar
3. Ask questions in natural language:
   - "What are the top 5 customers by total order amount?"
   - "Show me monthly sales trends"
   - "Which region has the most customers?"
4. View the generated SQL, results, and interpretation

### Using the API

```python
import requests

# Ask a question
response = requests.post(
    'http://localhost:8000/api/query',
    json={'question': 'What is the average order value?'}
)

result = response.json()
print(f"SQL Generated: {result['sql_generated']}")
print(f"Interpretation: {result['interpretation']}")
print(f"Data: {result['data']}")
```

### Using cURL

```bash
# Health check
curl http://localhost:8000/api/health

# Get schema
curl http://localhost:8000/api/schema

# Execute query
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the top customers by revenue?"}'
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src tests/

# Run specific test file
pytest tests/test_connectors.py
```

## ğŸ“ Project Structure

```
genai-data-platform/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ connectors/          # Data source connectors
â”‚   â”‚   â”œâ”€â”€ base.py          # Base connector interface
â”‚   â”‚   â””â”€â”€ postgresql.py    # PostgreSQL implementation
â”‚   â”œâ”€â”€ llm/                 # LLM providers
â”‚   â”‚   â”œâ”€â”€ base.py          # Base LLM interface
â”‚   â”‚   â””â”€â”€ openai_provider.py
â”‚   â”œâ”€â”€ rag/                 # RAG components (Stage 2)
â”‚   â”œâ”€â”€ orchestration/       # Core orchestration logic
â”‚   â”‚   â””â”€â”€ query_orchestrator.py
â”‚   â”œâ”€â”€ api/                 # FastAPI application
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ ui/                  # User interfaces
â”‚       â””â”€â”€ streamlit_app.py
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ data/                    # Data files (vector indices, etc.)
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ docs/                   # Documentation folder
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # Detailed architecture docs
â”‚   â”œâ”€â”€ ARCHITECTURE_VISUAL.md
â”‚   â”œâ”€â”€ GETTING_STARTED.md
â”‚   â”œâ”€â”€ PROJECT_CHECKLIST.md
â”‚   â””â”€â”€ INDEX.md
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

### LLM Provider Selection

Edit `.env` to use different models:

```bash
# OpenAI
LLM_MODEL=gpt-4                # More accurate but expensive
LLM_MODEL=gpt-3.5-turbo        # Faster and cheaper

# Temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.1
```

### Database Configuration

```bash
DB_HOST=localhost              # Database host
DB_PORT=5432                   # Database port
DB_NAME=analytics              # Database name
DB_USER=postgres               # Username
DB_PASSWORD=your_password      # Password
DB_SCHEMA=public              # Schema to query
```

## ğŸ› ï¸ Development Roadmap

### âœ… Stage 1: Foundation
- [x] PostgreSQL & SQLite connectors
- [x] OpenAI, Gemini & Anthropic LLM integration
- [x] Basic SQL generation
- [x] Query execution with validation
- [x] FastAPI endpoints
- [x] Streamlit UI

### âœ… Stage 2: SQL Optimization & Self-Correction
- [x] Advanced prompt engineering (few-shot, JOIN logic)
- [x] Schema enrichment with distinct categorical values
- [x] Autonomous SQL error correction loop
- [x] Exponential backoff for API rate limits

### âœ… Stage 3: RAG Implementation
- [x] Document ingestion pipeline (Markdown)
- [x] Vector store integration (ChromaDB)
- [x] Intent routing (SQL vs. Knowledge Base)
- [x] Retrieval-Augmented Generation for policy queries

### âœ… Stage 4: Enterprise Expansion
- [x] MySQL & SQLite connectors
- [x] BigQuery & Redshift connectors
- [x] DynamoDB (NoSQL) support
- [x] Global constant centralization for enterprise safety
- [x] Multi-source YAML configuration with env substitution

### âœ… Stage 5: Production Readiness
- [x] Authentication & RBAC
- [x] Query caching layer (Redis)
- [x] Performance monitoring with Prometheus/Grafana
- [ ] Advanced result visualization (Charts/Graphs)

## ğŸ› Troubleshooting

### Common Issues

**API won't start:**
- Check if port 8000 is available: `lsof -i :8000`
- Verify environment variables are set: `cat .env`
- Check database connection: `psql -h localhost -U postgres`

**LLM errors:**
- Verify OpenAI API key is valid
- Check API quota and billing
- Ensure internet connectivity

**Database connection errors:**
- Verify PostgreSQL is running: `pg_isready`
- Check credentials in `.env`
- Test connection: `psql -h localhost -U postgres -d analytics`

**Empty/incorrect SQL generation:**
- Check database schema is accessible
- Verify tables have data
- Try rephrasing the question
- Check LLM model configuration

## ğŸ“Š Performance Considerations

- **SQL Generation**: ~2-5 seconds per query (depends on LLM)
- **Query Execution**: Varies by query complexity
- **Token Usage**: ~500-2000 tokens per query
- **Cost**: ~$0.002-0.01 per query (GPT-3.5 Turbo)

## ğŸ”’ Security

- Only SELECT queries are allowed by default
- SQL injection prevention through validation
- Parameterized queries where possible
- Row limits automatically applied
- Query timeout controls

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“§ Support

For questions or issues:
- Check the documentation in `/docs`
- Review the architecture guide: `ARCHITECTURE.md`
- Open an issue on GitHub

## ğŸ™ Acknowledgments

Built with:
- FastAPI - Web framework
- LangChain - LLM orchestration
- OpenAI - Language models
- Streamlit - UI framework
- PostgreSQL - Database

---

**Happy Querying! ğŸš€**
